---
title: "Measure Theory"
description: "Sigma-algebras, the Lebesgue integral, Lp spaces, and abstract measure."
parent: mathematics/analysis
order: 4
color: "#ef4444"
difficulty: advanced
prerequisites: ["mathematics/analysis/real-analysis"]
status: draft
author: agent
lastEditedBy: agent
lastUpdated: "2026-02-28"
---

Measure theory is the rigorous mathematical framework for assigning sizes to sets and building a theory of integration that goes far beyond what the Riemann integral can handle. Developed at the turn of the twentieth century, primarily by Henri Lebesgue, it resolved deep pathologies in real analysis and became the indispensable foundation for probability, functional analysis, and much of modern mathematics. Where classical calculus asks "what is the area under this curve," measure theory asks the more fundamental question: what does it even mean to assign a size to an arbitrary subset of the real line?

## Foundations of Measure Theory

The conceptual starting point is the observation that not every subset of $\mathbb{R}$ should be expected to have a well-defined length. The classical notion of length works perfectly for intervals: the length of $[a, b]$ is $b - a$. But attempts to assign lengths to arbitrary sets run into serious trouble. In 1905, Giuseppe Vitali constructed the first example of a non-measurable set — a subset of $[0,1]$ that cannot be assigned any length consistent with the properties we demand of a reasonable size function. This showed that some restriction on which sets we measure is unavoidable.

The solution is to work not with all subsets, but with a carefully chosen collection called a **sigma-algebra** (or **$\sigma$-algebra**). A $\sigma$-algebra on a set $X$ is a collection $\mathcal{F}$ of subsets of $X$ satisfying three axioms: the empty set $\emptyset$ belongs to $\mathcal{F}$; if $A \in \mathcal{F}$ then its complement $A^c \in \mathcal{F}$; and if $A_1, A_2, A_3, \ldots$ is any countable sequence of sets in $\mathcal{F}$, then their union $\bigcup_{n=1}^\infty A_n$ also belongs to $\mathcal{F}$. Sets belonging to $\mathcal{F}$ are called **measurable sets**. The pair $(X, \mathcal{F})$ is called a **measurable space**.

The most important $\sigma$-algebra in analysis is the **Borel $\sigma$-algebra** $\mathcal{B}(\mathbb{R})$, defined as the smallest $\sigma$-algebra on $\mathbb{R}$ that contains all open sets. It also contains all closed sets, all countable intersections of open sets ($G_\delta$ sets), all countable unions of closed sets ($F_\sigma$ sets), and much more. Virtually every set one encounters in analysis is a Borel set.

A **measure** on a measurable space $(X, \mathcal{F})$ is a function $\mu: \mathcal{F} \to [0, \infty]$ satisfying two properties. First, $\mu(\emptyset) = 0$. Second, **countable additivity**: for any countable collection of pairwise disjoint sets $A_1, A_2, \ldots$ in $\mathcal{F}$,

$$\mu\!\left(\bigcup_{n=1}^\infty A_n\right) = \sum_{n=1}^\infty \mu(A_n).$$

The triple $(X, \mathcal{F}, \mu)$ is a **measure space**. Countable additivity is what separates a measure from a merely finitely additive set function, and this property is essential for passing limits through integrals. When $\mu(X) = 1$, the measure is a **probability measure** and the triple is a **probability space** in the sense of Andrei Kolmogorov's 1933 axiomatization.

The **Lebesgue measure** $\lambda$ on $\mathbb{R}$ is the unique measure on the Borel $\sigma$-algebra that assigns to each interval its length: $\lambda([a,b]) = b - a$. Its construction proceeds via the **Lebesgue outer measure** $\lambda^*$, defined for any subset $A \subseteq \mathbb{R}$ by covering $A$ with countably many open intervals and taking the infimum of the total length:

$$\lambda^*(A) = \inf\!\left\{ \sum_{n=1}^\infty (b_n - a_n) : A \subseteq \bigcup_{n=1}^\infty (a_n, b_n) \right\}.$$

The outer measure is defined on all subsets of $\mathbb{R}$, but it is only countably additive on the measurable sets selected by the **Carathéodory criterion**: a set $E$ is Lebesgue measurable if for every subset $A \subseteq \mathbb{R}$,

$$\lambda^*(A) = \lambda^*(A \cap E) + \lambda^*(A \cap E^c).$$

The collection of all Lebesgue measurable sets forms a $\sigma$-algebra that strictly contains the Borel $\sigma$-algebra and on which $\lambda^*$ is a complete measure — meaning every subset of a null set is measurable. A set $N$ has **measure zero** (is a **null set**) if $\lambda(N) = 0$; the Cantor set is a famous example of an uncountable null set. Properties that hold everywhere except on a null set are said to hold **almost everywhere**, abbreviated **a.e.**

## Measurable Functions and Lebesgue Integration

With a measure space $(X, \mathcal{F}, \mu)$ in hand, we need a notion of function compatible with the $\sigma$-algebra. A function $f: X \to \mathbb{R}$ is **measurable** if the preimage of every Borel set is measurable: for every $B \in \mathcal{B}(\mathbb{R})$, we require $f^{-1}(B) \in \mathcal{F}$. Equivalently, $f$ is measurable if and only if for every $c \in \mathbb{R}$, the set $\{x \in X : f(x) > c\}$ is measurable. Continuous functions are measurable, pointwise limits of measurable functions are measurable, and the class of measurable functions is closed under all algebraic operations and limits — precisely the properties needed for a robust integration theory.

The Lebesgue integral is built in stages. First, a **simple function** is a measurable function taking only finitely many values: $\phi = \sum_{k=1}^n c_k \mathbf{1}_{A_k}$ where $A_k$ are measurable sets and $\mathbf{1}_{A_k}$ is the indicator function of $A_k$. Its integral is defined in the obvious way:

$$\int_X \phi \, d\mu = \sum_{k=1}^n c_k \, \mu(A_k).$$

For a **non-negative measurable function** $f \geq 0$, the integral is defined as the supremum over all simple functions dominated by $f$:

$$\int_X f \, d\mu = \sup\left\{ \int_X \phi \, d\mu : \phi \text{ simple}, \; 0 \leq \phi \leq f \right\}.$$

For a general measurable function, write $f = f^+ - f^-$ where $f^+ = \max(f, 0)$ and $f^- = \max(-f, 0)$ are both non-negative, and set $\int_X f \, d\mu = \int_X f^+ \, d\mu - \int_X f^- \, d\mu$, provided at least one of these is finite. When both are finite, $f$ is called **integrable** or in $L^1(\mu)$.

The power of this construction is revealed by the convergence theorems. The **Monotone Convergence Theorem** states that if $0 \leq f_1 \leq f_2 \leq \cdots$ is an increasing sequence of non-negative measurable functions converging pointwise to $f$, then

$$\lim_{n \to \infty} \int_X f_n \, d\mu = \int_X f \, d\mu.$$

**Fatou's Lemma** gives a one-sided inequality for general sequences: if $f_n \geq 0$, then

$$\int_X \liminf_{n \to \infty} f_n \, d\mu \leq \liminf_{n \to \infty} \int_X f_n \, d\mu.$$

The most versatile result is the **Dominated Convergence Theorem** (DCT): if $f_n \to f$ pointwise almost everywhere and there exists an integrable function $g$ with $|f_n| \leq g$ for all $n$, then

$$\lim_{n \to \infty} \int_X f_n \, d\mu = \int_X f \, d\mu.$$

The Riemann integral, by contrast, cannot pass limits through integrals without uniform convergence — a far more restrictive condition. Lebesgue showed that a bounded function on $[a, b]$ is Riemann integrable if and only if it is continuous almost everywhere, and in that case the Riemann and Lebesgue integrals agree. Functions like Dirichlet's characteristic function of the rationals — zero on irrationals, one on rationals — are not Riemann integrable but are trivially Lebesgue integrable with integral zero, since the rationals form a null set.

## Product Measures and Fubini's Theorem

When two measure spaces $(X, \mathcal{F}, \mu)$ and $(Y, \mathcal{G}, \nu)$ are given, we want to build a measure on the Cartesian product $X \times Y$ that extends both. The **product $\sigma$-algebra** $\mathcal{F} \otimes \mathcal{G}$ is the smallest $\sigma$-algebra on $X \times Y$ containing all **measurable rectangles** $A \times B$ with $A \in \mathcal{F}$ and $B \in \mathcal{G}$. The **product measure** $\mu \otimes \nu$ is the unique measure on $\mathcal{F} \otimes \mathcal{G}$ satisfying

$$(\mu \otimes \nu)(A \times B) = \mu(A) \cdot \nu(B)$$

for all measurable rectangles. Existence and uniqueness of the product measure follows from the Carathéodory extension theorem, provided $\mu$ and $\nu$ are $\sigma$-finite — meaning that the whole space can be covered by countably many sets of finite measure.

**Fubini's Theorem** is the cornerstone result that justifies computing double integrals as iterated integrals. It has two complementary parts. For non-negative measurable functions (**Tonelli's Theorem**): if $f: X \times Y \to [0, \infty]$ is $\mathcal{F} \otimes \mathcal{G}$-measurable, then the iterated integrals are well-defined and equal:

$$\int_{X \times Y} f \, d(\mu \otimes \nu) = \int_X \!\left( \int_Y f(x, y) \, d\nu(y) \right) d\mu(x) = \int_Y \!\left( \int_X f(x, y) \, d\mu(x) \right) d\nu(y).$$

For integrable functions (**Fubini's Theorem proper**): if $f \in L^1(\mu \otimes \nu)$, then for $\mu$-almost every $x$ the section $y \mapsto f(x,y)$ is $\nu$-integrable, and the same iterated integral formula holds.

The hypothesis that $f$ be integrable (or non-negative) is genuinely necessary. The classic counterexample involves the unit square $[0,1]^2$ with Lebesgue measure: define $f(x,y) = (x^2 - y^2)/(x^2 + y^2)^2$ for $(x,y) \neq (0,0)$ and $f(0,0) = 0$. Then $\int_0^1 \left(\int_0^1 f(x,y)\, dy\right) dx = \pi/4$ while $\int_0^1 \left(\int_0^1 f(x,y)\, dx\right) dy = -\pi/4$ — the two iterated integrals disagree because $f \notin L^1([0,1]^2)$. Fubini's Theorem tells us that when the iterated integrals disagree, the function cannot be absolutely integrable over the product space.

Fubini's theorem underlies Cavalieri's principle — the ancient observation that two solids with equal cross-sectional areas at every height have equal volume — and it is the rigorous justification for change-of-variables formulas involving coordinate transformations in multiple dimensions.

## Signed Measures and Decomposition Theorems

A natural generalization allows a measure to take negative values. A **signed measure** on $(X, \mathcal{F})$ is a function $\nu: \mathcal{F} \to [-\infty, \infty]$ satisfying $\nu(\emptyset) = 0$ and countable additivity, but now allowed to be negative, subject to the constraint that it takes at most one of the values $+\infty$ or $-\infty$. Signed measures arise naturally as differences of two ordinary measures and as indefinite integrals: if $f$ is an integrable function and $\mu$ is a measure, then $\nu(A) = \int_A f \, d\mu$ defines a signed measure.

The **Jordan Decomposition Theorem** shows that every signed measure $\nu$ can be written uniquely as a difference $\nu = \nu^+ - \nu^-$ of two mutually singular positive measures, called the **positive variation** and **negative variation**. Two measures $\mu$ and $\nu$ are **mutually singular**, written $\mu \perp \nu$, if there exist disjoint sets $P, N$ with $X = P \cup N$ such that $\mu$ is concentrated on $P$ and $\nu$ is concentrated on $N$. The **total variation** measure is $|\nu| = \nu^+ + \nu^-$, and the **total variation norm** $\|\nu\| = |\nu|(X)$ makes the space of signed measures on $(X, \mathcal{F})$ into a Banach space.

The companion result to Jordan decomposition is the **Hahn Decomposition Theorem**: for any signed measure $\nu$, there exist disjoint sets $P$ and $N$ with $X = P \cup N$ such that $\nu$ is non-negative on every measurable subset of $P$ and non-positive on every measurable subset of $N$. The sets $P$ and $N$ are essentially unique (up to $\nu$-null sets) and are called the **positive** and **negative parts** of the Hahn decomposition.

The key concept relating two measures is **absolute continuity**. A measure $\nu$ is **absolutely continuous** with respect to a measure $\mu$, written $\nu \ll \mu$, if every $\mu$-null set is also a $\nu$-null set: whenever $\mu(A) = 0$, we have $\nu(A) = 0$. The intuition is that $\nu$ cannot see anything that $\mu$ cannot see.

The **Radon-Nikodym Theorem** characterizes absolute continuity analytically: if $\mu$ and $\nu$ are $\sigma$-finite measures on $(X, \mathcal{F})$ and $\nu \ll \mu$, then there exists a non-negative measurable function $f$, unique up to $\mu$-null sets, such that

$$\nu(A) = \int_A f \, d\mu \quad \text{for all } A \in \mathcal{F}.$$

The function $f$ is called the **Radon-Nikodym derivative** or **density** of $\nu$ with respect to $\mu$, and is written $f = d\nu/d\mu$. This notation deliberately evokes the chain rule: if $\lambda \ll \nu \ll \mu$, then $d\lambda/d\mu = (d\lambda/d\nu)(d\nu/d\mu)$ $\mu$-almost everywhere. Otto Nikodym proved this result in 1930 (following earlier work by Johann Radon in 1913), and it is one of the most powerful tools in analysis and probability, providing the theoretical foundation for conditional expectation, likelihood ratios in statistics, and changes of probability measure in stochastic calculus.

The **Lebesgue Decomposition Theorem** extends this: for any two $\sigma$-finite measures $\mu$ and $\nu$, there is a unique decomposition $\nu = \nu_{ac} + \nu_s$ where $\nu_{ac} \ll \mu$ and $\nu_s \perp \mu$. Applied to the Stieltjes measure of a function of bounded variation, this recovers the classical decomposition into absolutely continuous and singular parts.

## Lp Spaces

The **$L^p$ spaces** organize integrable functions into a family of Banach spaces parametrized by $p \in [1, \infty]$. For $1 \leq p < \infty$, the space $L^p(X, \mu)$ consists of equivalence classes of measurable functions $f: X \to \mathbb{R}$ (with two functions identified if they agree almost everywhere) satisfying

$$\|f\|_p = \left( \int_X |f|^p \, d\mu \right)^{1/p} < \infty.$$

The space $L^\infty(X, \mu)$ consists of essentially bounded functions, with norm $\|f\|_\infty = \text{ess}\sup |f|$ — the smallest $M$ such that $|f| \leq M$ almost everywhere. These norms make each $L^p$ space a complete normed vector space, i.e., a **Banach space**; this completeness was proved by Fischer and Riesz independently in 1907. The special case $p = 2$ gives a **Hilbert space** $L^2(X, \mu)$ with inner product $\langle f, g \rangle = \int_X f g \, d\mu$.

The fundamental inequalities governing $L^p$ spaces are **Hölder's inequality** and **Minkowski's inequality**. If $1/p + 1/q = 1$ (with $p$ and $q$ called **conjugate exponents**), then for $f \in L^p$ and $g \in L^q$,

$$\int_X |fg| \, d\mu \leq \|f\|_p \|g\|_q.$$

This is Hölder's inequality; the case $p = q = 2$ is the Cauchy-Schwarz inequality. Minkowski's inequality asserts the triangle inequality for the $L^p$ norm: $\|f + g\|_p \leq \|f\|_p + \|g\|_p$. Both inequalities ultimately rest on Young's inequality for products: $ab \leq a^p/p + b^q/q$ for $a, b \geq 0$ and conjugate exponents $p, q$.

The dual space of $L^p(X, \mu)$ for $1 \leq p < \infty$ is characterized by the **Riesz Representation Theorem for $L^p$**: every bounded linear functional $\Lambda: L^p \to \mathbb{R}$ is of the form $\Lambda(f) = \int_X fg \, d\mu$ for a unique $g \in L^q$, and $\|\Lambda\| = \|g\|_q$. This means $(L^p)^* \cong L^q$, so $L^p$ and $L^q$ are isometrically isomorphic as Banach spaces when $1 < p < \infty$. For $p = 1$, the dual is $L^\infty$; for $p = \infty$, the dual is strictly larger than $L^1$.

Different modes of convergence interact in subtle ways within and across $L^p$ spaces. Convergence in $L^p$ norm implies convergence in measure, and convergence in measure implies the existence of an almost-everywhere convergent subsequence. Almost-everywhere convergence does not imply $L^p$ convergence in general (as the "sliding bump" sequence on $[0,1]$ shows), but with a dominating function it does, by the Dominated Convergence Theorem. **Egorov's Theorem** bridges these: on a finite measure space, almost-everywhere convergence implies nearly-uniform convergence — given $\epsilon > 0$, there is a set $E$ with $\mu(E) < \epsilon$ outside of which convergence is uniform.

The $L^p$ spaces are separable for $1 \leq p < \infty$ (when the underlying measure space is $\sigma$-finite and separable), reflexive for $1 < p < \infty$, and neither reflexive nor separable in general for $p = 1$ or $p = \infty$. These structural properties make $L^2$ especially tractable in functional analysis and quantum mechanics, while $L^1$ and $L^\infty$ require more careful handling.

## Hausdorff Measures and Fractal Dimension

Standard Lebesgue measure captures the $n$-dimensional volume of subsets of $\mathbb{R}^n$, but it says nothing useful about sets with fractional or intermediate dimension — a curve in $\mathbb{R}^3$ has zero 3-dimensional volume and infinite 1-dimensional measure unless we use the right notion. **Hausdorff measures** fill this gap by allowing the dimension parameter to be any non-negative real number.

Fix $s \geq 0$ and $\delta > 0$. For any set $A \subseteq \mathbb{R}^n$, define

$$\mathcal{H}^s_\delta(A) = \inf\!\left\{ \sum_{k=1}^\infty (\text{diam}\, U_k)^s : A \subseteq \bigcup_{k=1}^\infty U_k,\; \text{diam}\, U_k \leq \delta \right\},$$

where the infimum is over all countable covers of $A$ by sets of diameter at most $\delta$. The **$s$-dimensional Hausdorff measure** is then $\mathcal{H}^s(A) = \lim_{\delta \to 0} \mathcal{H}^s_\delta(A)$. Felix Hausdorff introduced this construction in 1919. For each set $A$, there is a critical value $d$ such that $\mathcal{H}^s(A) = \infty$ for $s < d$ and $\mathcal{H}^s(A) = 0$ for $s > d$. This critical value is the **Hausdorff dimension** $\dim_H(A)$.

For familiar sets, Hausdorff dimension agrees with topological intuition: a smooth curve has dimension 1, a smooth surface has dimension 2, an open set in $\mathbb{R}^n$ has dimension $n$. The power of the concept is in its application to irregular sets. The **Cantor set** $C$, constructed by iteratively removing the middle thirds of intervals, is uncountable yet has Lebesgue measure zero. Its Hausdorff dimension is $\log 2 / \log 3 \approx 0.631$. The **Sierpinski triangle**, obtained by repeatedly removing central triangles, has Hausdorff dimension $\log 3 / \log 2 \approx 1.585$.

These are examples of **self-similar sets** — sets that are unions of scaled copies of themselves. For a self-similar set satisfying the **open set condition** (a technical disjointness requirement), if it is the union of $N$ copies each scaled by ratio $r$, then its Hausdorff dimension satisfies the **Moran equation**: $N \cdot r^s = 1$, giving $s = \log N / \log(1/r)$. For the Cantor set, $N = 2$ and $r = 1/3$, confirming $s = \log 2 / \log 3$.

Hausdorff measure is a Borel regular measure on $\mathbb{R}^n$, and $\mathcal{H}^n$ coincides with $n$-dimensional Lebesgue measure up to a normalizing constant. One dimensional Hausdorff measure $\mathcal{H}^1$ restricted to a smooth curve gives arc length. The theory of Hausdorff measures is the entry point to **geometric measure theory**, which studies rectifiable sets, minimal surfaces, and variational problems using the full machinery of measure theory. Benoit Mandelbrot popularized fractal dimension in the 1970s, and the concept now appears in physics (turbulence, critical phenomena), biology (branching structures), and image processing.

## Covering Theorems and Differentiation

A recurring theme in analysis is recovering local information about a function or measure from averaged quantities. The **Lebesgue Differentiation Theorem** is the measure-theoretic analogue of the fundamental theorem of calculus: for any locally integrable function $f: \mathbb{R}^n \to \mathbb{R}$,

$$\lim_{r \to 0^+} \frac{1}{\lambda(B(x,r))} \int_{B(x,r)} f(y) \, dy = f(x) \quad \text{for a.e. } x \in \mathbb{R}^n,$$

where $B(x,r)$ is the ball of radius $r$ centered at $x$ and $\lambda$ denotes Lebesgue measure. In other words, the average value of $f$ over smaller and smaller balls centered at $x$ converges to $f(x)$ at almost every point. A point where this holds is called a **Lebesgue point** of $f$, and the theorem says that almost every point is a Lebesgue point.

The proof of the Lebesgue Differentiation Theorem relies on **covering lemmas** — geometric results that allow one to extract disjoint or nearly-disjoint subcollections from a covering. The most important is the **Vitali Covering Lemma**: given any collection of balls $\{B_\alpha\}$ in $\mathbb{R}^n$ with $\sup_\alpha \text{diam}(B_\alpha) < \infty$, one can extract a countable disjoint subcollection $\{B_k\}$ such that every ball in the original collection is contained in $5B_k$ (the ball with the same center but five times the radius) for some $k$:

$$\bigcup_\alpha B_\alpha \subseteq \bigcup_k 5B_k.$$

The Vitali lemma is used to bound the **Hardy-Littlewood maximal function** $Mf(x) = \sup_{r > 0} \frac{1}{\lambda(B(x,r))} \int_{B(x,r)} |f(y)| \, dy$. The **Hardy-Littlewood Maximal Inequality** asserts that for $f \in L^1(\mathbb{R}^n)$ and any $\alpha > 0$,

$$\lambda(\{x : Mf(x) > \alpha\}) \leq \frac{C_n}{\alpha} \|f\|_{L^1},$$

where $C_n$ depends only on the dimension $n$. This **weak-type $(1,1)$ estimate** is the cornerstone of the proof of the differentiation theorem and appears throughout harmonic analysis. The **Besicovitch Covering Theorem** provides an alternative covering result that works in metric spaces without relying on the Euclidean structure, making it useful for differentiating measures in more abstract settings.

Covering theorems also underlie the differentiation theory of monotone functions. A monotone function $f: [a,b] \to \mathbb{R}$ is differentiable almost everywhere — this is **Lebesgue's Theorem on Monotone Functions**, proved in 1904. The key insight is that the set of points where $f$ fails to be differentiable can be covered by collections of intervals where the difference quotients oscillate, and the Vitali lemma shows this set must have measure zero. A function is **absolutely continuous** on $[a,b]$ if and only if it is the indefinite integral of an $L^1$ function, in which case the fundamental theorem of calculus holds: $f(x) - f(a) = \int_a^x f'(t) \, dt$ for all $x$. Absolute continuity is strictly stronger than continuity and bounded variation, and it is precisely the condition under which the Lebesgue integral serves as the inverse of differentiation.

The differentiation theorem and its relatives connect back to the Radon-Nikodym theorem: the density $d\nu/d\mu$ can often be recovered as a pointwise limit of difference quotients, and the Lebesgue Decomposition of a measure into absolutely continuous and singular parts corresponds to the decomposition of a function of bounded variation into its absolutely continuous and singular parts. These connections make the differentiation theory of measures a unifying thread running through real analysis, harmonic analysis, and geometric measure theory.
