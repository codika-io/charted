---
title: Analysis
description: The rigorous study of change and continuity — limits, differentiation, integration, and the infinite made precise.
parent: mathematics
order: 7
color: "#ef4444"
difficulty: intermediate
prerequisites: ["mathematics/algebra", "mathematics/topology"]
status: draft
author: agent
lastEditedBy: agent
lastUpdated: "2026-02-28"
---

Analysis is calculus made honest. When Newton and Leibniz independently invented calculus in the seventeenth century, they wielded the concept of "infinitely small quantities" — infinitesimals — with breathtaking effectiveness yet troubling imprecision. Their methods predicted the motions of planets and the shapes of curves, but the logical foundations were shaky enough that critics, most famously Bishop Berkeley, could call infinitesimals "ghosts of departed quantities." The two centuries that followed were a long, painstaking effort to replace intuition with rigour, and the result is one of the most powerful and far-reaching branches of mathematics ever assembled.

The decisive turn came in the nineteenth century. Augustin-Louis Cauchy recast the derivative and integral in terms of limits, giving mathematicians a definition they could reason about without invoking mysterious infinitely small numbers. Karl Weierstrass sharpened this further with the now-canonical epsilon-delta formulation, banishing any remaining metaphysical fog. Bernhard Riemann gave a precise definition of the integral that bears his name and, in the process, exposed subtle questions about which functions could be integrated at all. These three mathematicians transformed calculus from a powerful but philosophically murky toolkit into a rigorous discipline — and opened doors to problems that the original inventors could not have imagined.

The starting point for any serious study is Real Analysis, which revisits the real number line with new eyes. Here the intuitions of school calculus — continuity, limits, derivatives, and integrals — are rebuilt from first principles. The experience is initially humbling: things that seemed obvious become theorems requiring careful proof. But the payoff is a dependable framework on which everything else can rest. From there, Complex Analysis extends the machinery to functions of a complex variable, revealing a world of startling elegance. Leonhard Euler glimpsed this world early, and Riemann mapped much of it, discovering that differentiability in the complex sense forces functions to be far more constrained and beautiful than their real counterparts. Results that are difficult or impossible over the real numbers become almost effortless once complex methods are applied, which is why complex analysis finds its way into number theory, fluid mechanics, and quantum physics alike.

A more subtle challenge that occupied mathematicians into the early twentieth century was integration itself. The Riemann integral works well for continuous functions, but breaks down in ways that matter deeply for probability theory and Fourier analysis. Henri Lebesgue resolved this with a sweeping redefinition of the integral based on measure — a way of assigning "size" to sets far more general than intervals. Measure Theory, developed by Lebesgue and extended by many others, is the rigorous foundation beneath modern probability, statistics, and much of harmonic analysis. It is also the language in which the deepest results about convergence and approximation can be stated cleanly.

Once one has a notion of measure, the natural next step is to study spaces of functions rather than individual functions. This is the domain of Functional Analysis, pioneered by figures such as David Hilbert and Stefan Banach. A function space is an infinite-dimensional analogue of a vector space, and the tools of linear algebra — norms, inner products, eigenvalues — carry over with remarkable fidelity. Hilbert spaces underpin quantum mechanics; Banach spaces provide the abstract setting for solving integral and differential equations. The subject is a crossroads where analysis, geometry, and algebra converge.

Closely related is Harmonic Analysis, which traces its origins to Joseph Fourier's audacious claim that almost any function can be decomposed into a sum of sines and cosines. Fourier's insight, initially controversial, proved foundational for physics, signal processing, and pure mathematics alike. Modern harmonic analysis goes far beyond Fourier series, studying how functions can be decomposed and reconstructed across a wide range of settings, from locally compact groups to wavelets and beyond.

The study of change leads naturally to Ordinary Differential Equations, which describe how quantities evolve over time according to rules involving their own rates of change. From Newton's laws of motion to population dynamics to electrical circuits, ODEs are the language of continuous change. Partial Differential Equations extend this to phenomena that vary across both space and time — heat, sound, electrostatics, fluid flow, and the geometry of minimal surfaces. The twentieth century brought profound new tools for PDEs, drawing on functional analysis, harmonic analysis, and geometry in equal measure. Henri Poincaré's qualitative approach to differential equations also gave birth to Dynamical Systems, the study of long-term behaviour: stability, chaos, strange attractors, and the sensitivity to initial conditions that makes weather prediction inherently limited.

Together, these eight sub-topics — Real Analysis, Complex Analysis, Measure Theory, Functional Analysis, Harmonic Analysis, Ordinary Differential Equations, Partial Differential Equations, and Dynamical Systems — form a tightly woven fabric. Learning one deepens your understanding of the others. The thread that runs through all of them is a single, recurring question: what does it mean for something to be close to something else, and what can we conclude from that closeness? Analysis is the sustained, rigorous, and endlessly productive attempt to answer it.
